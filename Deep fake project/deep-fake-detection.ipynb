{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-16T17:04:04.121209Z",
     "iopub.status.busy": "2025-03-16T17:04:04.120619Z",
     "iopub.status.idle": "2025-03-16T17:05:41.575893Z",
     "shell.execute_reply": "2025-03-16T17:05:41.574834Z",
     "shell.execute_reply.started": "2025-03-16T17:04:04.121119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -U --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:41.579463Z",
     "iopub.status.busy": "2025-03-16T17:05:41.579155Z",
     "iopub.status.idle": "2025-03-16T17:05:45.521262Z",
     "shell.execute_reply": "2025-03-16T17:05:45.520103Z",
     "shell.execute_reply.started": "2025-03-16T17:05:41.579405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import tensorflow as tf\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np\n",
    "import imageio # type: ignore\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:45.524138Z",
     "iopub.status.busy": "2025-03-16T17:05:45.523796Z",
     "iopub.status.idle": "2025-03-16T17:05:45.594271Z",
     "shell.execute_reply": "2025-03-16T17:05:45.593228Z",
     "shell.execute_reply.started": "2025-03-16T17:05:45.524085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/kaggle/input/deepfake-detection-challenge'\n",
    "TRAIN_SAMPLE_FOLDER = 'train_sample_videos'\n",
    "TEST_FOLDER = 'test_videos'\n",
    "\n",
    "print(f\"train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
    "print(f\"test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:45.597141Z",
     "iopub.status.busy": "2025-03-16T17:05:45.596337Z",
     "iopub.status.idle": "2025-03-16T17:05:46.061998Z",
     "shell.execute_reply": "2025-03-16T17:05:46.060945Z",
     "shell.execute_reply.started": "2025-03-16T17:05:45.597050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_sample_metadata = pd.read_json('/kaggle/input/deepfake-detection-challenge/train_sample_videos/metadata.json').T\n",
    "train_sample_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:46.063966Z",
     "iopub.status.busy": "2025-03-16T17:05:46.063637Z",
     "iopub.status.idle": "2025-03-16T17:05:46.290243Z",
     "shell.execute_reply": "2025-03-16T17:05:46.288922Z",
     "shell.execute_reply.started": "2025-03-16T17:05:46.063908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_sample_metadata.groupby('label')['label'].count().plot(figsize=(5,5),kind='bar',title='The Label in the Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:46.292237Z",
     "iopub.status.busy": "2025-03-16T17:05:46.291849Z",
     "iopub.status.idle": "2025-03-16T17:05:46.302037Z",
     "shell.execute_reply": "2025-03-16T17:05:46.300440Z",
     "shell.execute_reply.started": "2025-03-16T17:05:46.292178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_sample_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:46.305200Z",
     "iopub.status.busy": "2025-03-16T17:05:46.304726Z",
     "iopub.status.idle": "2025-03-16T17:05:46.321401Z",
     "shell.execute_reply": "2025-03-16T17:05:46.320096Z",
     "shell.execute_reply.started": "2025-03-16T17:05:46.305132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].sample(5).index)\n",
    "f_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:46.323459Z",
     "iopub.status.busy": "2025-03-16T17:05:46.323042Z",
     "iopub.status.idle": "2025-03-16T17:05:46.336508Z",
     "shell.execute_reply": "2025-03-16T17:05:46.335160Z",
     "shell.execute_reply.started": "2025-03-16T17:05:46.323382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def capture_image_from_video(video_path):\n",
    "    # Capture video\n",
    "    capture_image = cv2.VideoCapture(video_path)\n",
    "    ret, frame = capture_image.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Could not read frame from {video_path}\")\n",
    "        return\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    ax = fig.add_subplot(111)  \n",
    "    ax.imshow(frame)\n",
    "    plt.show()\n",
    "    capture_image.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:46.339332Z",
     "iopub.status.busy": "2025-03-16T17:05:46.338629Z",
     "iopub.status.idle": "2025-03-16T17:05:48.358328Z",
     "shell.execute_reply": "2025-03-16T17:05:48.357220Z",
     "shell.execute_reply.started": "2025-03-16T17:05:46.339203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for video_file in f_train_sample_video:\n",
    "    capture_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:48.360184Z",
     "iopub.status.busy": "2025-03-16T17:05:48.359822Z",
     "iopub.status.idle": "2025-03-16T17:05:48.373589Z",
     "shell.execute_reply": "2025-03-16T17:05:48.371223Z",
     "shell.execute_reply.started": "2025-03-16T17:05:48.360125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "r_train_sample_video = list(train_sample_metadata.loc[train_sample_metadata.label=='REAL'].sample(5).index)\n",
    "r_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:48.379135Z",
     "iopub.status.busy": "2025-03-16T17:05:48.378106Z",
     "iopub.status.idle": "2025-03-16T17:05:50.231588Z",
     "shell.execute_reply": "2025-03-16T17:05:50.230370Z",
     "shell.execute_reply.started": "2025-03-16T17:05:48.378490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for video_file in r_train_sample_video:\n",
    "    capture_image_from_video(os.path.join(DATA_FOLDER,TRAIN_SAMPLE_FOLDER,video_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:50.239841Z",
     "iopub.status.busy": "2025-03-16T17:05:50.236385Z",
     "iopub.status.idle": "2025-03-16T17:05:50.378993Z",
     "shell.execute_reply": "2025-03-16T17:05:50.377925Z",
     "shell.execute_reply.started": "2025-03-16T17:05:50.239719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f_videos = list(train_sample_metadata.loc[train_sample_metadata.label=='FAKE'].index)\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def play_video(video_file,subset=TRAIN_SAMPLE_FOLDER):\n",
    "    video_url = open(os.path.join(DATA_FOLDER,subset,video_file),'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(video_url).decode()\n",
    "    return HTML(\"\"\"<video width=500 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" %data_url)\n",
    "play_video(f_videos[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:50.381255Z",
     "iopub.status.busy": "2025-03-16T17:05:50.380943Z",
     "iopub.status.idle": "2025-03-16T17:05:50.957069Z",
     "shell.execute_reply": "2025-03-16T17:05:50.955733Z",
     "shell.execute_reply.started": "2025-03-16T17:05:50.381196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "max_seq_length = 20\n",
    "num_features = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:50.959241Z",
     "iopub.status.busy": "2025-03-16T17:05:50.958819Z",
     "iopub.status.idle": "2025-03-16T17:05:51.072997Z",
     "shell.execute_reply": "2025-03-16T17:05:51.071982Z",
     "shell.execute_reply.started": "2025-03-16T17:05:50.959176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y,x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y :start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(img_size, img_size)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while 1:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "            \n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:51.075475Z",
     "iopub.status.busy": "2025-03-16T17:05:51.075076Z",
     "iopub.status.idle": "2025-03-16T17:05:57.627906Z",
     "shell.execute_reply": "2025-03-16T17:05:57.626946Z",
     "shell.execute_reply.started": "2025-03-16T17:05:51.075409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pretrain_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "    weights = \"imagenet\",\n",
    "    include_top=False,\n",
    "    pooling=\"avg\",\n",
    "    input_shape = (img_size,img_size,3)\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "    \n",
    "    inputs = keras.Input((img_size,img_size,3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "    \n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "feature_extractor = pretrain_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:57.630038Z",
     "iopub.status.busy": "2025-03-16T17:05:57.629628Z",
     "iopub.status.idle": "2025-03-16T17:05:57.642039Z",
     "shell.execute_reply": "2025-03-16T17:05:57.640949Z",
     "shell.execute_reply.started": "2025-03-16T17:05:57.629961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = list(df.index)\n",
    "    labels = df[\"label\"].values\n",
    "    labels = np.array(labels=='FAKE').astype(np.int)\n",
    "    \n",
    "    frame_masks = np.zeros(shape=(num_samples, max_seq_length), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, max_seq_length, num_features), dtype=\"float32\" \n",
    "    )\n",
    "    \n",
    "    for idx, path in enumerate(video_paths):\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "        \n",
    "        temp_frame_mask = np.zeros(shape=(1, max_seq_length,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(shape=(1, max_seq_length, num_features), dtype=\"float32\")\n",
    "        \n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0] \n",
    "            length = min(max_seq_length, video_length) #if length is over 20s ,only cut 20s\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] =feature_extractor.predict(batch[None, j, :])\n",
    "            temp_frame_mask[i, :length] =1 # 1 = not masked, 0 = masked ->give 1 when there are images ,otherwise 0 for padding\n",
    "        \n",
    "        frame_features[idx,] =temp_frame_features.squeeze() #squeeze array for training\n",
    "        frame_masks[idx,] =temp_frame_mask.squeeze()\n",
    "    \n",
    "    return (frame_features, frame_masks), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:57.647591Z",
     "iopub.status.busy": "2025-03-16T17:05:57.647137Z",
     "iopub.status.idle": "2025-03-16T17:05:59.977223Z",
     "shell.execute_reply": "2025-03-16T17:05:59.976199Z",
     "shell.execute_reply.started": "2025-03-16T17:05:57.647509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_set , Test_set = train_test_split(train_sample_metadata, test_size=0.3,random_state=42,\n",
    "                                       stratify=train_sample_metadata['label'])\n",
    "print(Train_set.shape, Test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:05:59.979389Z",
     "iopub.status.busy": "2025-03-16T17:05:59.979072Z",
     "iopub.status.idle": "2025-03-16T17:06:00.079639Z",
     "shell.execute_reply": "2025-03-16T17:06:00.078453Z",
     "shell.execute_reply.started": "2025-03-16T17:05:59.979339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = prepare_all_videos(Train_set, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(Test_set, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set:{train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set:{train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:06:00.081357Z",
     "iopub.status.busy": "2025-03-16T17:06:00.081092Z",
     "iopub.status.idle": "2025-03-16T17:06:02.011031Z",
     "shell.execute_reply": "2025-03-16T17:06:02.010116Z",
     "shell.execute_reply.started": "2025-03-16T17:06:00.081313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "frame_features_input = keras.Input((max_seq_length, num_features))\n",
    "mask_input = keras.Input((max_seq_length,),dtype=\"bool\")\n",
    "\n",
    "x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask = mask_input)\n",
    "x = keras.layers.GRU(8)(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model([frame_features_input, mask_input], output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:06:02.013597Z",
     "iopub.status.busy": "2025-03-16T17:06:02.013181Z",
     "iopub.status.idle": "2025-03-16T17:06:22.162999Z",
     "shell.execute_reply": "2025-03-16T17:06:22.161996Z",
     "shell.execute_reply.started": "2025-03-16T17:06:02.013523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('./', save_weights_only=True, save_best_only=True)\n",
    "history = model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_data=([test_data[0], test_data[1]], test_labels),\n",
    "        callbacks=[checkpoint],\n",
    "        epochs=epochs,\n",
    "        batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:06:22.165759Z",
     "iopub.status.busy": "2025-03-16T17:06:22.165293Z",
     "iopub.status.idle": "2025-03-16T17:06:22.212757Z",
     "shell.execute_reply": "2025-03-16T17:06:22.211663Z",
     "shell.execute_reply.started": "2025-03-16T17:06:22.165673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/fake_video_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:06:22.214945Z",
     "iopub.status.busy": "2025-03-16T17:06:22.214459Z",
     "iopub.status.idle": "2025-03-16T17:06:22.221646Z",
     "shell.execute_reply": "2025-03-16T17:06:22.220124Z",
     "shell.execute_reply.started": "2025-03-16T17:06:22.214857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"/kaggle/working\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:06:22.223938Z",
     "iopub.status.busy": "2025-03-16T17:06:22.223476Z",
     "iopub.status.idle": "2025-03-16T17:06:31.263751Z",
     "shell.execute_reply": "2025-03-16T17:06:31.262278Z",
     "shell.execute_reply.started": "2025-03-16T17:06:22.223853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_videos = pd.DataFrame(list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER))), columns=['video'])\n",
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, max_seq_length,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(max_seq_length, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    frames = load_video(os.path.join(DATA_FOLDER, TEST_FOLDER,path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    return model.predict([frame_features, frame_mask])[0]\n",
    "    \n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n",
    "\n",
    "\n",
    "test_video = np.random.choice(test_videos[\"video\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "if(sequence_prediction(test_video)>=0.5):\n",
    "    print(f'The predicted class of the video is FAKE')\n",
    "else:\n",
    "    print(f'The predicted class of the video is REAL')\n",
    "\n",
    "play_video(test_video,TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T17:07:28.420063Z",
     "iopub.status.busy": "2025-03-16T17:07:28.419515Z",
     "iopub.status.idle": "2025-03-16T17:07:40.320200Z",
     "shell.execute_reply": "2025-03-16T17:07:40.318451Z",
     "shell.execute_reply.started": "2025-03-16T17:07:28.419993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "# Load the trained model\n",
    "model = keras.models.load_model(\"/kaggle/working/fake_video_detection_model.h5\")\n",
    "\n",
    "# Define constants\n",
    "max_seq_length = 20  # Should be the same as in training\n",
    "num_features = 2048   # Adjust according to feature extractor\n",
    "\n",
    "# Load the feature extractor (same one used in training)\n",
    "feature_extractor = keras.applications.InceptionV3(include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))\n",
    "\n",
    "def load_video(video_path, max_frames=max_seq_length, frame_size=(224, 224)):\n",
    "    \"\"\"Loads video frames and resizes them to the required shape.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count >= max_frames:\n",
    "            break\n",
    "        frame = cv2.resize(frame, frame_size)  # Resize to match feature extractor\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    if len(frames) < max_frames:\n",
    "        # Pad with zeros if less frames\n",
    "        frames += [np.zeros((224, 224, 3))] * (max_frames - len(frames))\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "def preprocess_video(video_path):\n",
    "    \"\"\"Preprocesses a video and extracts features for prediction.\"\"\"\n",
    "    frames = load_video(video_path)\n",
    "    frames = frames[None, ...]  # Add batch dimension\n",
    "    \n",
    "    frame_mask = np.zeros((1, max_seq_length), dtype=\"bool\")\n",
    "    frame_features = np.zeros((1, max_seq_length, num_features), dtype=\"float32\")\n",
    "\n",
    "    video_length = frames.shape[1]\n",
    "    length = min(max_seq_length, video_length)\n",
    "\n",
    "    for i in range(length):\n",
    "        frame_features[0, i, :] = feature_extractor.predict(frames[:, i, :, :, :])\n",
    "    frame_mask[0, :length] = 1\n",
    "\n",
    "    return [frame_features, frame_mask]\n",
    "\n",
    "# Path to the test video\n",
    "video_path = \"/kaggle/input/deepfake-detection-challenge/test_videos/bjyaxvggle.mp4\"\n",
    "\n",
    "# Preprocess the video\n",
    "video_data = preprocess_video(video_path)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(video_data)\n",
    "predicted_label = \"FAKE\" if prediction[0][0] > 0.5 else \"REAL\"\n",
    "\n",
    "print(f\"Prediction: {predicted_label} (Confidence: {prediction[0][0]:.4f})\")\n",
    "\n",
    "# Function to display the video in a Kaggle Notebook\n",
    "def display_video(video_path):\n",
    "    \"\"\"Encodes and displays video in a Kaggle Notebook\"\"\"\n",
    "    video_encoded = base64.b64encode(open(video_path, \"rb\").read()).decode('utf-8')\n",
    "    video_tag = f'''\n",
    "    <video width=\"600\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    '''\n",
    "    return HTML(video_tag)\n",
    "\n",
    "# Display the video\n",
    "display_video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 858837,
     "sourceId": 16880,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 29844,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
